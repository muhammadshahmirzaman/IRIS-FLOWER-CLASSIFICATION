{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7614559,"sourceType":"datasetVersion","datasetId":4434378}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os  \nfrom PIL import Image\nimport nibabel as nib\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.048964Z","iopub.status.idle":"2024-11-26T19:57:54.049250Z","shell.execute_reply.started":"2024-11-26T19:57:54.049110Z","shell.execute_reply":"2024-11-26T19:57:54.049125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"csv_path = \"/kaggle/input/adni-1-5t-fastsurfer-quickseg/ADNI-1.5T-FastSurfer-QuickSeg/ADNI1_Screening_1.5T_1_29_2024.csv\"\nbase = \"/kaggle/input/adni-1-5t-fastsurfer-quickseg/ADNI-1.5T-FastSurfer-QuickSeg/\"\ncsv_data = pd.read_csv(csv_path)\ndf = pd.DataFrame(csv_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.050702Z","iopub.status.idle":"2024-11-26T19:57:54.051149Z","shell.execute_reply.started":"2024-11-26T19:57:54.050917Z","shell.execute_reply":"2024-11-26T19:57:54.050939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input/\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.052343Z","iopub.status.idle":"2024-11-26T19:57:54.052652Z","shell.execute_reply.started":"2024-11-26T19:57:54.052498Z","shell.execute_reply":"2024-11-26T19:57:54.052514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(base)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.053805Z","iopub.status.idle":"2024-11-26T19:57:54.054124Z","shell.execute_reply.started":"2024-11-26T19:57:54.053985Z","shell.execute_reply":"2024-11-26T19:57:54.054001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mri_images_AD = np.array([(os.path.join(base, \"AD\", img, \"mri\", \"orig.mgz\"), \"AD\") for img in os.listdir(os.path.join(base, \"AD\"))], dtype=object)\nmri_images_CN = np.array([(os.path.join(base, \"CN\", img, \"mri\", \"orig.mgz\"), \"CN\") for img in os.listdir(os.path.join(base, \"CN\"))], dtype=object)\nmri_images_MCI = np.array([(os.path.join(base, \"MCI\", img, \"mri\", \"orig.mgz\"), \"MCI\") for img in os.listdir(os.path.join(base, \"MCI\"))], dtype=object)\nmri_images_AD_1=mri_images_AD\nmri_images_CN_1=mri_images_CN\nmri_images_MCI_1=mri_images_MCI","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.055394Z","iopub.status.idle":"2024-11-26T19:57:54.055656Z","shell.execute_reply.started":"2024-11-26T19:57:54.055527Z","shell.execute_reply":"2024-11-26T19:57:54.055541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Path to your .mgz file (update this with your file path)\nmgz_file_path = '/kaggle/input/adni-1-5t-fastsurfer-quickseg/ADNI-1.5T-FastSurfer-QuickSeg/CN/I107934.nii/mri/orig.mgz'\n\n# Load the .mgz file using nibabel\nmgz_image = nib.load(mgz_file_path)\n\n# Get the image data as a NumPy array\nimage_data = mgz_image.get_fdata()\n\n# Print the shape of the image data (optional)\nprint(f\"Image shape: {image_data.shape}\")\n\n# Choose a middle slice along a dimension (for example, the middle slice along the Z-axis)\nmiddle_slice = image_data.shape[2] // 2\n\n# Extract the middle slice (you can change the axis or slice index depending on your data)\nslice_data = image_data[:, :, middle_slice]\n\n# Plot the slice\nplt.figure(figsize=(8, 8))\nplt.imshow(slice_data.T, cmap='gray', origin='lower')  # Transpose for correct orientation\nplt.colorbar()  # Optional: display color bar\nplt.title(f\"Middle Slice of {mgz_file_path}\")\nplt.axis('off')  # Hide axis labels\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.056876Z","iopub.status.idle":"2024-11-26T19:57:54.057164Z","shell.execute_reply.started":"2024-11-26T19:57:54.057025Z","shell.execute_reply":"2024-11-26T19:57:54.057040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mri_images_CN_1[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.058211Z","iopub.status.idle":"2024-11-26T19:57:54.058480Z","shell.execute_reply.started":"2024-11-26T19:57:54.058342Z","shell.execute_reply":"2024-11-26T19:57:54.058355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to extract .nii filename safely\ndef extract_nii_filename(file_path):\n    # Split the path by '/' and check if there are enough elements\n    path_parts = file_path.split('/')\n    \n    # Ensure the split contains enough parts (at least 3 parts from the end)\n    if len(path_parts) >= 3:\n        return path_parts[-3]  # Extract .nii filename\n    else:\n        return None  # Return None for unexpected paths\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.059663Z","iopub.status.idle":"2024-11-26T19:57:54.059991Z","shell.execute_reply.started":"2024-11-26T19:57:54.059838Z","shell.execute_reply":"2024-11-26T19:57:54.059861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the extraction function to each list\nmri_images_AD = np.array([[extract_nii_filename(file_info[0]), file_info[1]] \n                          for file_info in mri_images_AD if extract_nii_filename(file_info[0])])\n\nmri_images_CN = np.array([[extract_nii_filename(file_info[0]), file_info[1]] \n                          for file_info in mri_images_CN if extract_nii_filename(file_info[0])])\n\nmri_images_MCI = np.array([[extract_nii_filename(file_info[0]), file_info[1]] \n                           for file_info in mri_images_MCI if extract_nii_filename(file_info[0])])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.061951Z","iopub.status.idle":"2024-11-26T19:57:54.062378Z","shell.execute_reply.started":"2024-11-26T19:57:54.062148Z","shell.execute_reply":"2024-11-26T19:57:54.062171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_mri_images_AD,X_split_mri_images_AD,y_train_mri_images_AD,y_split_mri_images_AD = train_test_split(mri_images_AD[:,0],mri_images_AD[:,1],test_size=0.3)\nX_Dev_mri_images_AD,X_test_mri_images_AD,y_Dev_mri_images_AD,y_test_mri_images_AD = train_test_split(X_split_mri_images_AD,y_split_mri_images_AD,train_size=0.5)\nX_train_mri_images_CN,X_split_mri_images_CN,y_train_mri_images_CN,y_split_mri_images_CN = train_test_split(mri_images_CN[:,0],mri_images_CN[:,1],test_size=0.3)\nX_Dev_mri_images_CN,X_test_mri_images_CN,y_Dev_mri_images_CN,y_test_mri_images_CN = train_test_split(X_split_mri_images_CN,y_split_mri_images_CN,test_size=0.5)\nX_train_mri_images_MCI,X_split_mri_images_MCI,y_train_mri_images_MCI,y_split_mri_images_MCI = train_test_split(mri_images_MCI[:,0],mri_images_MCI[:,1],test_size=0.3)\nX_Dev_mri_images_MCI,X_test_mri_images_MCI,y_Dev_mri_images_MCI,y_test_mri_images_MCI = train_test_split(X_split_mri_images_MCI,y_split_mri_images_MCI,test_size=0.5)\nmri_images_train = np.concatenate((X_train_mri_images_AD, X_train_mri_images_CN, X_train_mri_images_MCI), axis=0)\n# mri_labels_train = np.concatenate((y_train_mri_images_AD, y_train_mri_images_CN, y_train_mri_images_MCI), axis=0)\nmri_images_dev = np.concatenate((X_Dev_mri_images_AD, X_Dev_mri_images_CN, X_Dev_mri_images_MCI), axis=0)\n# mri_labels_dev = np.concatenate((y_Dev_mri_images_AD, y_Dev_mri_images_CN, y_Dev_mri_images_MCI), axis=0)\nmri_images_test = np.concatenate((X_test_mri_images_AD, X_test_mri_images_CN, X_test_mri_images_MCI), axis=0)\n# mri_labels_test = np.concatenate((y_test_mri_images_AD, y_test_mri_images_CN, y_test_mri_images_MCI), axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.063522Z","iopub.status.idle":"2024-11-26T19:57:54.063969Z","shell.execute_reply.started":"2024-11-26T19:57:54.063719Z","shell.execute_reply":"2024-11-26T19:57:54.063741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_mri_images_AD_1,X_split_mri_images_AD_1,y_train_mri_images_AD_1,y_split_mri_images_AD_1 = train_test_split(mri_images_AD_1[:,0],mri_images_AD_1[:,1],test_size=0.3)\nX_Dev_mri_images_AD_1,X_test_mri_images_AD_1,y_Dev_mri_images_AD_1,y_test_mri_images_AD_1 = train_test_split(X_split_mri_images_AD_1,y_split_mri_images_AD_1,train_size=0.5)\n\nX_train_mri_images_CN_1,X_split_mri_images_CN_1,y_train_mri_images_CN_1,y_split_mri_images_CN_1 = train_test_split(mri_images_CN_1[:,0],mri_images_CN_1[:,1],test_size=0.3)\nX_Dev_mri_images_CN_1,X_test_mri_images_CN_1,y_Dev_mri_images_CN_1,y_test_mri_images_CN_1 = train_test_split(X_split_mri_images_CN_1,y_split_mri_images_CN_1,test_size=0.5)\n\nX_train_mri_images_MCI_1,X_split_mri_images_MCI_1,y_train_mri_images_MCI_1,y_split_mri_images_MCI_1 = train_test_split(mri_images_MCI_1[:,0],mri_images_MCI_1[:,1],test_size=0.3)\nX_Dev_mri_images_MCI_1,X_test_mri_images_MCI_1,y_Dev_mri_images_MCI_1,y_test_mri_images_MCI_1 = train_test_split(X_split_mri_images_MCI_1,y_split_mri_images_MCI_1,test_size=0.5)\n\nmri_images_train_11 = np.concatenate((X_train_mri_images_AD_1, X_train_mri_images_CN_1, X_train_mri_images_MCI_1), axis=0)\nmri_labels_train_11 = np.concatenate((y_train_mri_images_AD_1, y_train_mri_images_CN_1, y_train_mri_images_MCI_1), axis=0)\n\nmri_images_dev_11 = np.concatenate((X_Dev_mri_images_AD_1, X_Dev_mri_images_CN_1, X_Dev_mri_images_MCI_1), axis=0)\nmri_labels_dev_11 = np.concatenate((y_Dev_mri_images_AD_1, y_Dev_mri_images_CN_1, y_Dev_mri_images_MCI_1), axis=0)\n\nmri_images_test_11 = np.concatenate((X_test_mri_images_AD_1, X_test_mri_images_CN_1, X_test_mri_images_MCI_1), axis=0)\nmri_labels_test_11 = np.concatenate((y_test_mri_images_AD_1, y_test_mri_images_CN_1, y_test_mri_images_MCI_1), axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.065377Z","iopub.status.idle":"2024-11-26T19:57:54.065800Z","shell.execute_reply.started":"2024-11-26T19:57:54.065583Z","shell.execute_reply":"2024-11-26T19:57:54.065606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mri_images_train_1 = mri_images_train_11[:14]\nmri_labels_train_1 = mri_labels_train_11[:14]\n\n# Extract 3 rows from the development set\nmri_images_dev_1 = mri_images_dev_11[:3]\nmri_labels_dev_1 = mri_labels_dev_11[:3]\n\n# Extract 3 rows from the test set\nmri_images_test_1 = mri_images_test_11[:3]\nmri_labels_test_1 = mri_labels_test_11[:3]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.067092Z","iopub.status.idle":"2024-11-26T19:57:54.067515Z","shell.execute_reply.started":"2024-11-26T19:57:54.067298Z","shell.execute_reply":"2024-11-26T19:57:54.067320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_column = np.concatenate([mri_images_test,mri_images_dev,mri_images_train])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.068905Z","iopub.status.idle":"2024-11-26T19:57:54.069174Z","shell.execute_reply.started":"2024-11-26T19:57:54.069042Z","shell.execute_reply":"2024-11-26T19:57:54.069057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for index, row in df.iterrows():\n    file_name = row['Image Data ID'] + \".nii\"\n    if file_name not in first_column:\n        df = df.drop(index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.070537Z","iopub.status.idle":"2024-11-26T19:57:54.070861Z","shell.execute_reply.started":"2024-11-26T19:57:54.070689Z","shell.execute_reply":"2024-11-26T19:57:54.070704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(first_column),len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.072340Z","iopub.status.idle":"2024-11-26T19:57:54.072730Z","shell.execute_reply.started":"2024-11-26T19:57:54.072586Z","shell.execute_reply":"2024-11-26T19:57:54.072602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.074132Z","iopub.status.idle":"2024-11-26T19:57:54.074429Z","shell.execute_reply.started":"2024-11-26T19:57:54.074290Z","shell.execute_reply":"2024-11-26T19:57:54.074305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train= df\ndf_test = df\ndf_dev  = df ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.075510Z","iopub.status.idle":"2024-11-26T19:57:54.075782Z","shell.execute_reply.started":"2024-11-26T19:57:54.075644Z","shell.execute_reply":"2024-11-26T19:57:54.075657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the extraction function to each list\ntrain = np.array([extract_nii_filename(file_info) \n                          for file_info in mri_images_train_1 if extract_nii_filename(file_info)])\n\ntest = np.array([extract_nii_filename(file_info) \n                          for file_info in mri_images_test_1 if extract_nii_filename(file_info)])\n\ndev = np.array([extract_nii_filename(file_info)\n                           for file_info in mri_images_dev_1 if extract_nii_filename(file_info)])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.076775Z","iopub.status.idle":"2024-11-26T19:57:54.077099Z","shell.execute_reply.started":"2024-11-26T19:57:54.076958Z","shell.execute_reply":"2024-11-26T19:57:54.076974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for index, row in df_train.iterrows():\n    file_name = row['Image Data ID'] + \".nii\"\n    if file_name not in train:\n        df_train = df_train.drop(index)\n\ndf_train = df_train.sort_values(by='Image Data ID', ascending=True)\ndf_train.reset_index(drop=True,inplace=True)\ndf_train.head(2),len(df_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.078149Z","iopub.status.idle":"2024-11-26T19:57:54.078416Z","shell.execute_reply.started":"2024-11-26T19:57:54.078285Z","shell.execute_reply":"2024-11-26T19:57:54.078298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for index, row in df_dev.iterrows():\n    file_name = row['Image Data ID'] + \".nii\"\n    if file_name not in dev:\n        df_dev = df_dev.drop(index)\n\ndf_dev = df_dev.sort_values(by='Image Data ID', ascending=True)\ndf_dev.reset_index(drop=True,inplace=True)\ndf_dev.tail(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.079560Z","iopub.status.idle":"2024-11-26T19:57:54.079989Z","shell.execute_reply.started":"2024-11-26T19:57:54.079752Z","shell.execute_reply":"2024-11-26T19:57:54.079775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for index, row in df.iterrows():\n    file_name = row['Image Data ID'] + \".nii\"\n    if file_name not in test:\n        df_test = df_test.drop(index)\n\n\ndf_test = df_test.sort_values(by='Image Data ID', ascending=True)\ndf_test.reset_index(drop=True,inplace=True)\ndf_test.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.080855Z","iopub.status.idle":"2024-11-26T19:57:54.081279Z","shell.execute_reply.started":"2024-11-26T19:57:54.081046Z","shell.execute_reply":"2024-11-26T19:57:54.081068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Zip the lists together\nzipped_train = list(zip(train,mri_images_train_1))\nzipped_test = list(zip(test,mri_images_test_1))\nzipped_dev = list(zip(dev,mri_images_dev_1))\n\n# Sort based on the only .nii files\nzipped_sorted_train = sorted(zipped_train, key=lambda x: x[0])  \nzipped_sorted_test = sorted(zipped_test, key=lambda x: x[0])  \nzipped_sorted_dev = sorted(zipped_dev, key=lambda x: x[0])  \n\n# Unzip the lists after sorting\nsorted_names_train , sorted_file_paths_train = zip(*zipped_sorted_train)\nsorted_names_test  , sorted_file_paths_test = zip(*zipped_sorted_test)\nsorted_names_dev   , sorted_file_paths_dev = zip(*zipped_sorted_dev)\n\n# Convert back to lists (if you prefer them as lists)\nsorted_file_paths_train = list(sorted_file_paths_train)\nsorted_names_train = list(sorted_names_train)\nsorted_file_paths_test = list(sorted_file_paths_test)\nsorted_names_test = list(sorted_names_test)\nsorted_file_paths_dev = list(sorted_file_paths_dev)\nsorted_names_dev = list(sorted_names_dev)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.082909Z","iopub.status.idle":"2024-11-26T19:57:54.083335Z","shell.execute_reply.started":"2024-11-26T19:57:54.083107Z","shell.execute_reply":"2024-11-26T19:57:54.083131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sorted_file_paths_train[0],df_train.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.084499Z","iopub.status.idle":"2024-11-26T19:57:54.084928Z","shell.execute_reply.started":"2024-11-26T19:57:54.084696Z","shell.execute_reply":"2024-11-26T19:57:54.084718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Making Female '0' and Male '1' to load them into dataloader","metadata":{}},{"cell_type":"code","source":"df_dev['Sex'] = df_dev['Sex'].map({'F': 0, 'M': 1})\ndf_test['Sex'] = df_test['Sex'].map({'F': 0, 'M': 1})\ndf_train['Sex'] = df_train['Sex'].map({'F': 0, 'M': 1})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.086375Z","iopub.status.idle":"2024-11-26T19:57:54.086804Z","shell.execute_reply.started":"2024-11-26T19:57:54.086576Z","shell.execute_reply":"2024-11-26T19:57:54.086601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# try:\n#     # Load the .mgz file\n#     mgz_file = nib.load(mri_images_train_3D[0])\n\n#     # Get the MRI data as a numpy array\n#     mri_data = mgz_file.get_fdata()\n\n#     # Print the shape of the matrix\n#     print(f\"Shape of the MRI data matrix: {mri_data.shape}\")\n\n# except FileNotFoundError as e:\n#     print(f\"Error: {e}\")\n# except Exception as e:\n#     print(f\"An unexpected error occurred: {e}\")\n\n# if np.all(mri_data == 0):\n#     print(\"The MRI matrix contains only zeros.\")\n# else:\n#     print(\"The MRI matrix contains non-zero values.\")\n\n# # Print a small portion of the matrix (slice) for inspection\n# print(\"Sample MRI matrix values (slice at index 0):\")\n# print(mri_data[:, :, 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.088691Z","iopub.status.idle":"2024-11-26T19:57:54.089123Z","shell.execute_reply.started":"2024-11-26T19:57:54.088907Z","shell.execute_reply":"2024-11-26T19:57:54.088930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load MRI image using nibabel\n# mri_images_train_3D = []\n\n# for i in range(len(sorted_file_paths_train)):\n#     # Load image and convert to tensor\n#     img = nib.load(sorted_file_paths_train[i]).get_fdata()\n#     img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel and batch dimensions\n    \n#     # Move to GPU\n#     img_tensor = img_tensor.to('cuda')\n    \n#     # Resize to 256x256x256\n#     desired_shape = (256, 256, 256)\n#     resized_img_tensor = F.interpolate(img_tensor, size=desired_shape, mode='trilinear', align_corners=False)\n    \n#     # Append to list and move back to CPU if needed\n#     mri_images_train_3D.append(resized_img_tensor.squeeze().cpu().numpy())\n\n# print(\"Resized image shape:\", mri_images_train_3D[2].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.090344Z","iopub.status.idle":"2024-11-26T19:57:54.090759Z","shell.execute_reply.started":"2024-11-26T19:57:54.090538Z","shell.execute_reply":"2024-11-26T19:57:54.090560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load MRI image using nibabel\n# mri_images_dev_3D = []\n\n# for i in range(len(sorted_file_paths_dev)):\n#     # Load image and convert to tensor\n#     img = nib.load(sorted_file_paths_dev[i]).get_fdata()\n#     img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel and batch dimensions\n    \n#     # Move to GPU\n#     img_tensor = img_tensor.to('cuda')\n    \n#     # Resize to 256x256x256\n#     desired_shape = (256, 256, 256)\n#     resized_img_tensor = F.interpolate(img_tensor, size=desired_shape, mode='trilinear', align_corners=False)\n    \n#     # Append to list and move back to CPU if needed\n#     mri_images_dev_3D.append(resized_img_tensor.squeeze().cpu().numpy())\n\n# print(\"Resized image shape:\", mri_images_dev_3D[2].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.092305Z","iopub.status.idle":"2024-11-26T19:57:54.092579Z","shell.execute_reply.started":"2024-11-26T19:57:54.092440Z","shell.execute_reply":"2024-11-26T19:57:54.092454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load MRI image using nibabel\n# mri_images_test_3D = []\n\n# for i in range(len(sorted_file_paths_test)):\n#     # Load image and convert to tensor\n#     img = nib.load(sorted_file_paths_test[i]).get_fdata()\n#     img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add channel and batch dimensions\n    \n#     # Move to GPU\n#     img_tensor = img_tensor.to('cuda')\n    \n#     # Resize to 256x256x256\n#     desired_shape = (256, 256, 256)\n#     resized_img_tensor = F.interpolate(img_tensor, size=desired_shape, mode='trilinear', align_corners=False)\n    \n#     # Append to list and move back to CPU if needed\n#     mri_images_test_3D.append(resized_img_tensor.squeeze().cpu().numpy())\n\n# print(\"Resized image shape:\", mri_images_test_3D[2].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.093613Z","iopub.status.idle":"2024-11-26T19:57:54.093954Z","shell.execute_reply.started":"2024-11-26T19:57:54.093761Z","shell.execute_reply":"2024-11-26T19:57:54.093776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reshaped_tensors_train = []\n# for img_tensor in mri_images_train_3D:\n#     # Ensure the tensor is not None\n#     if img_tensor is not None:\n#         # Convert numpy array to PyTorch tensor\n#         img_tensor = torch.from_numpy(img_tensor)\n#         # Add the channel dimension [1, D, H, W]\n#         img_tensor = img_tensor.unsqueeze(0)\n#         reshaped_tensors_train.append(img_tensor)\n\n# # Stack all tensors to form a single tensor of shape [N, 1, D, H, W]\n# # N: Number of images, C: 1 (grayscale), D: Depth, H: Height, W: Width\n# tensor_data_train = torch.stack(reshaped_tensors_train)  # Shape: [N, 1, D, H, W]\n\n# print(f\"Final tensor shape: {tensor_data_train.shape}\")  # Should print [N, 1, D, H, W]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.095154Z","iopub.status.idle":"2024-11-26T19:57:54.095416Z","shell.execute_reply.started":"2024-11-26T19:57:54.095286Z","shell.execute_reply":"2024-11-26T19:57:54.095299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reshaped_tensors_test = []\n# for img_tensor in mri_images_test_3D:\n#     # Ensure the tensor is not None\n#     if img_tensor is not None:\n#         # Convert numpy array to PyTorch tensor\n#         img_tensor = torch.from_numpy(img_tensor)\n#         # Add the channel dimension [1, D, H, W]\n#         img_tensor = img_tensor.unsqueeze(0)\n#         reshaped_tensors_test.append(img_tensor)\n\n# # Stack all tensors to form a single tensor of shape [N, 1, D, H, W]\n# # N: Number of images, C: 1 (grayscale), D: Depth, H: Height, W: Width\n# tensor_data_test = torch.stack(reshaped_tensors_test)  # Shape: [N, 1, D, H, W]\n\n# print(f\"Final tensor shape: {tensor_data_test.shape}\")  # Should print [N, 1, D, H, W]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.096701Z","iopub.status.idle":"2024-11-26T19:57:54.097014Z","shell.execute_reply.started":"2024-11-26T19:57:54.096873Z","shell.execute_reply":"2024-11-26T19:57:54.096888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# reshaped_tensors_dev = []\n# for img_tensor in mri_images_dev_3D:\n#     # Ensure the tensor is not None\n#     if img_tensor is not None:\n#         # Convert numpy array to PyTorch tensor\n#         img_tensor = torch.from_numpy(img_tensor)\n#         # Add the channel dimension [1, D, H, W]\n#         img_tensor = img_tensor.unsqueeze(0)\n#         reshaped_tensors_dev.append(img_tensor)\n\n# # Stack all tensors to form a single tensor of shape [N, 1, D, H, W]\n# # N: Number of images, C: 1 (grayscale), D: Depth, H: Height, W: Width\n# tensor_data_dev = torch.stack(reshaped_tensors_dev)  # Shape: [N, 1, D, H, W]\n\n# print(f\"Final tensor shape: {tensor_data_dev.shape}\")  # Should print [N, 1, D, H, W]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.098255Z","iopub.status.idle":"2024-11-26T19:57:54.098562Z","shell.execute_reply.started":"2024-11-26T19:57:54.098415Z","shell.execute_reply":"2024-11-26T19:57:54.098430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.ndimage import zoom\n\nclass NiftiDataset():\n    def __init__(self, image_paths, label_paths, label_map, age_sex_df, target_shape=(256, 256, 256)):\n        self.image_paths = image_paths\n        self.label_paths = label_paths\n        self.label_map = label_map\n        self.age_sex_df = age_sex_df  # DataFrame with age and sex\n        self.target_shape = target_shape  # Desired image dimensions (e.g., 256x256x256)\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def resize_image(self, img):\n        # Calculate the zoom factor for resizing\n        zoom_factors = [t / s for t, s in zip(self.target_shape, img.shape)]\n        resized_img = zoom(img, zoom_factors, order=3)  # Use cubic interpolation (order=3)\n        return resized_img\n\n    def __getitem__(self, idx):\n        # Get image path and corresponding label\n        image_path = self.image_paths[idx]\n        label_str = self.label_paths[idx]  # Assuming label is a string like 'CN'\n\n        # Convert label string to numerical index\n        label_index = self.label_map[label_str]\n\n        # Load and preprocess image data\n        img = nib.load(image_path).get_fdata()  # Load image data as a NumPy array\n        resized_img = self.resize_image(img)  # Resize the image\n\n        # Add channel dimension (1 for grayscale MRI images)\n        image_tensor = torch.from_numpy(resized_img).unsqueeze(0).float()  # Shape: [1, 256, 256, 256]\n\n        # Convert label to PyTorch tensor\n        label_tensor = torch.tensor(label_index, dtype=torch.long)  # Shape: [1]\n\n        # Get age and sex from DataFrame\n        age = self.age_sex_df.loc[idx, 'Age']  # Assuming 'Age' column exists\n        sex = self.age_sex_df.loc[idx, 'Sex']  # Assuming 'Sex' column exists\n\n        # Convert age and sex to tensors\n        age_tensor = torch.tensor(age, dtype=torch.float32)\n        sex_tensor = torch.tensor(sex, dtype=torch.long)  # Assuming sex is categorical (0 for male, 1 for female)\n\n        return image_tensor, label_tensor, age_tensor, sex_tensor\n\n\n# Define the label map\nlabel_map = {\n    'AD': 0,\n    'CN': 1,\n    'MCI': 2\n}\n\n# Example usage\n# Assuming sorted_file_paths_train, sorted_file_paths_test, etc., are lists of file paths\n# and df_train, df_test, etc., are DataFrames with 'Age' and 'Sex' columns\ntrain_dataset = NiftiDataset(sorted_file_paths_train, mri_labels_train_1, label_map, df_train[['Age', 'Sex']])\ntest_dataset = NiftiDataset(sorted_file_paths_test, mri_labels_test_1, label_map, df_test[['Age', 'Sex']])\ndev_dataset = NiftiDataset(sorted_file_paths_dev, mri_labels_dev_1, label_map, df_dev[['Age', 'Sex']])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\ndev_loader = DataLoader(dev_dataset, batch_size=2, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.100029Z","iopub.status.idle":"2024-11-26T19:57:54.100297Z","shell.execute_reply.started":"2024-11-26T19:57:54.100165Z","shell.execute_reply":"2024-11-26T19:57:54.100179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx, (X, y, age, sex) in enumerate(dev_loader):\n    print(f\"Batch {idx}: X type: {type(X)}, shape: {X.shape}\")\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.101312Z","iopub.status.idle":"2024-11-26T19:57:54.101582Z","shell.execute_reply.started":"2024-11-26T19:57:54.101446Z","shell.execute_reply":"2024-11-26T19:57:54.101460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def createAlzheimerModel(printtoggle=False):\n\n    class AlzheimerNet(nn.Module):\n        def __init__(self, printtoggle):\n            super().__init__()\n\n            # Convolutional layers for 3D MRI images\n            self.conv1 = nn.Conv3d(1, 32, kernel_size=7, stride=1, padding=1)\n            self.conv2 = nn.Conv3d(32, 64, kernel_size=7, stride=1, padding=1)\n            self.conv3 = nn.Conv3d(64, 128, kernel_size=7, stride=1, padding=1)\n            self.conv4 = nn.Conv3d(128, 256, kernel_size=7, stride=1, padding=1)\n            self.conv5 = nn.Conv3d(256, 128, kernel_size=7, stride=1, padding=1)\n\n            # Compute the expected size after conv and pooling layers\n            self.fc_input_size = 128 * 4 * 4 * 4  # Flattened size from Conv layers\n\n            # Fully connected layers for image features\n            self.fc1 = nn.Linear(self.fc_input_size, 512)\n            self.fc2 = nn.Linear(512, 128)\n\n            # Additional branch for age and sex features\n            self.fc_age_sex = nn.Linear(2, 16)  # Age and Sex -> 16 features\n\n            # Combined layers\n            self.fc_combined = nn.Linear(128 + 16, 64)  # Combine image and auxiliary features\n            self.fc3 = nn.Linear(64, 32)\n            self.fc4 = nn.Linear(32, 32)\n\n            # Output layer (3 classes for Alzheimer's disease classification)\n            self.out = nn.Linear(32, 3)  # Specify the number of output classes\n\n            # Toggle for printing tensor sizes\n            self.print = printtoggle\n\n        def forward(self, x, age_sex):\n            if self.print: print(f'Input: {list(x.shape)}')\n\n            # Convolution -> MaxPool -> Activation\n            x = F.gelu(F.max_pool3d(self.conv1(x), 2))\n            if self.print: print(f'Layer conv1/pool1: {x.shape}')\n\n            x = F.gelu(F.max_pool3d(self.conv2(x), 2))\n            if self.print: print(f'Layer conv2/pool2: {x.shape}')\n\n            x = F.gelu(F.max_pool3d(self.conv3(x), 2))\n            if self.print: print(f'Layer conv3/pool3: {x.shape}')\n\n            x = F.gelu(F.max_pool3d(self.conv4(x), 2))\n            if self.print: print(f'Layer conv4/pool4: {x.shape}')\n\n            x = F.gelu(F.max_pool3d(self.conv5(x), 2))\n            if self.print: print(f'Layer conv5/pool5: {x.shape}')\n\n            # Flatten the tensor for the fully connected layers\n            x = x.view(x.size(0), -1)\n            if self.print: print(f'Flattened: {x.shape}')\n\n            # Fully connected layers for MRI features\n            x = F.gelu(self.fc1(x))\n            if self.print: print(f'Layer fc1: {x.shape}')\n\n            x = F.gelu(self.fc2(x))\n            if self.print: print(f'Layer fc2: {x.shape}')\n\n            # Process age and sex features\n            age_sex = F.gelu(self.fc_age_sex(age_sex))\n            if self.print: print(f'Age and Sex branch: {age_sex.shape}')\n            \n            # Combine MRI and age/sex features\n            x = torch.cat((x, age_sex), dim=1)  # Concatenate along feature dimension\n            if self.print: print(f'Combined features: {x.shape}')\n\n            x = F.gelu(self.fc_combined(x))\n            if self.print: print(f'Layer fc_combined: {x.shape}')\n\n            x = F.gelu(self.fc3(x))\n            if self.print: print(f'Layer fc3: {x.shape}')\n\n            x = F.gelu(self.fc4(x))\n            if self.print: print(f'Layer fc4: {x.shape}')\n\n            # Output layer\n            x = self.out(x)\n\n            return x\n\n    # Create the model instance\n    net = AlzheimerNet(printtoggle)\n\n    # Loss function (Cross-Entropy Loss for multi-class classification)\n    lossfun = nn.CrossEntropyLoss()\n\n    # Optimizer\n    optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=0.0001)\n\n    return net, lossfun, optimizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.102840Z","iopub.status.idle":"2024-11-26T19:57:54.103137Z","shell.execute_reply.started":"2024-11-26T19:57:54.102996Z","shell.execute_reply":"2024-11-26T19:57:54.103012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ACCESSING GPU","metadata":{}},{"cell_type":"code","source":"# use GPU if available\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.103964Z","iopub.status.idle":"2024-11-26T19:57:54.104220Z","shell.execute_reply.started":"2024-11-26T19:57:54.104093Z","shell.execute_reply":"2024-11-26T19:57:54.104106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model():\n    # Number of epochs\n    num_epochs = 5\n\n    # Create a new model\n    net, lossfun, optimizer = createAlzheimerModel()  # Assuming createAlzheimerModel is your model function\n\n    # Send the model to the GPU\n    net.to(device)\n\n    # Initialize lists to store loss and accuracy for each epoch\n    train_loss = torch.zeros(num_epochs)\n    dev_loss   = torch.zeros(num_epochs)\n    train_acc  = torch.zeros(num_epochs)\n    dev_acc    = torch.zeros(num_epochs)\n\n    # Loop over epochs\n    for epochi in range(num_epochs):\n\n        ### Training Phase\n        net.train()  # Set model to training mode\n        batch_loss = []\n        batch_acc  = []\n\n        for X, y, age, sex in train_loader:\n\n            # Send data to GPU\n            X = X.to(device)  # MRI images\n            y = y.to(device)  # Labels\n            age_sex = torch.stack([age, sex], dim=1).to(device)  # Combine age and sex into a tensor\n\n            # Forward pass and compute loss\n            y_hat = net(X, age_sex)\n            loss = lossfun(y_hat, y)\n\n            # Backpropagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Accumulate loss and accuracy for this batch\n            batch_loss.append(loss.item())\n            batch_acc.append(torch.mean((torch.argmax(y_hat, axis=1) == y).float()).item())\n\n        # Average loss and accuracy over the entire epoch for training\n        train_loss[epochi] = np.mean(batch_loss)\n        train_acc[epochi]  = 100 * np.mean(batch_acc)\n\n        ### Validation Phase (on dev set)\n        net.eval()  # Set model to evaluation mode\n        batch_loss = []\n        batch_acc  = []\n\n        for X, y, age, sex in dev_loader:\n\n            # Send data to GPU\n            X = X.to(device)  # MRI images\n            y = y.to(device)  # Labels\n            age_sex = torch.stack([age, sex], dim=1).to(device)  # Combine age and sex into a tensor\n\n            # Forward pass (no backpropagation during evaluation)\n            with torch.no_grad():\n                y_hat = net(X, age_sex)\n                loss = lossfun(y_hat, y)\n\n            # Accumulate loss and accuracy for this batch\n            batch_loss.append(loss.item())\n            batch_acc.append(torch.mean((torch.argmax(y_hat, axis=1) == y).float()).item())\n\n        # Average loss and accuracy over the entire epoch for validation\n        dev_loss[epochi] = np.mean(batch_loss)\n        dev_acc[epochi]  = 100 * np.mean(batch_acc)\n\n        # Optional: print progress after each epoch\n        print(f\"Epoch {epochi+1}/{num_epochs} - Train Loss: {train_loss[epochi]:.4f}, Train Acc: {train_acc[epochi]:.2f}%, \"\n              f\"Dev Loss: {dev_loss[epochi]:.4f}, Dev Acc: {dev_acc[epochi]:.2f}%\")\n\n    # Function output: return losses, accuracies, and the trained model\n    return train_loss, dev_loss, train_acc, dev_acc, net","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.105179Z","iopub.status.idle":"2024-11-26T19:57:54.105479Z","shell.execute_reply.started":"2024-11-26T19:57:54.105339Z","shell.execute_reply":"2024-11-26T19:57:54.105354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TRAIN MODEL","metadata":{}},{"cell_type":"code","source":"train_loss, dev_loss, train_acc, dev_acc, net = train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.106702Z","iopub.status.idle":"2024-11-26T19:57:54.107026Z","shell.execute_reply.started":"2024-11-26T19:57:54.106881Z","shell.execute_reply":"2024-11-26T19:57:54.106897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model():\n    # Number of epochs\n    num_epochs = 5\n\n    # Create a new model\n    net, lossfun, optimizer = createAlzheimerModel()  # Assuming createAlzheimerModel is your model function\n\n    # Send the model to the GPU\n    net.to(device)\n\n    # Initialize lists to store loss and accuracy for each epoch\n    test_loss   = torch.zeros(num_epochs)\n    test_acc    = torch.zeros(num_epochs)\n\n    # Loop over epochs\n    for epochi in range(num_epochs):\n\n        ### Training Phase\n        net.eval()  # Set model to evaluation mode\n        batch_loss = []\n        batch_acc  = []\n\n        for X, y, age, sex in test_loader:\n\n            # Send data to GPU\n            X = X.to(device)  # MRI images\n            y = y.to(device)  # Labels\n            age_sex = torch.stack([age, sex], dim=1).to(device)  # Combine age and sex into a tensor\n\n            # Forward pass (no backpropagation during evaluation)\n            with torch.no_grad():\n                y_hat = net(X, age_sex)\n                loss = lossfun(y_hat, y)\n\n            # Accumulate loss and accuracy for this batch\n            batch_loss.append(loss.item())\n            batch_acc.append(torch.mean((torch.argmax(y_hat, axis=1) == y).float()).item())\n\n        # Average loss and accuracy over the entire epoch for validation\n        test_loss[epochi] = np.mean(batch_loss)\n        test_acc[epochi]  = 100 * np.mean(batch_acc)\n\n        # Optional: print progress after each epoch\n        print(f\"Test Loss: {dev_loss[epochi]:.4f}, Test Acc: {dev_acc[epochi]:.2f}%\")\n\n    # Function output: return losses, accuracies, and the trained model\n    return test_loss, test_acc,net","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:58:17.144111Z","iopub.execute_input":"2024-11-26T19:58:17.144642Z","iopub.status.idle":"2024-11-26T19:58:17.151754Z","shell.execute_reply.started":"2024-11-26T19:58:17.144608Z","shell.execute_reply":"2024-11-26T19:58:17.150872Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"test_loss, test_acc, net = test_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:58:21.690050Z","iopub.execute_input":"2024-11-26T19:58:21.690385Z","iopub.status.idle":"2024-11-26T20:00:20.555134Z","shell.execute_reply.started":"2024-11-26T19:58:21.690354Z","shell.execute_reply":"2024-11-26T20:00:20.554323Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.0000, Test Acc: 100.00%\nTest Loss: 0.0000, Test Acc: 100.00%\nTest Loss: 0.0000, Test Acc: 100.00%\nTest Loss: 0.0000, Test Acc: 100.00%\nTest Loss: 0.0000, Test Acc: 100.00%\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metrics(train_loss, dev_loss, train_acc, dev_acc, test_loss, test_acc):\n    \"\"\"\n    Plot training and validation metrics along with test metrics.\n    \"\"\"\n    # Handle multi-element tensors for test_loss and test_acc\n    test_loss = test_loss.mean().item() if isinstance(test_loss, torch.Tensor) else test_loss\n    test_acc = test_acc.mean().item() if isinstance(test_acc, torch.Tensor) else test_acc\n\n    epochs = range(1, len(train_loss) + 1)\n\n    # Plot Loss\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_loss, label='Train Loss', marker='o')\n    plt.plot(epochs, dev_loss, label='Dev Loss', marker='o')\n    plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')  # Test loss as a horizontal line\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Loss Over Epochs')\n    plt.legend()\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_acc, label='Train Accuracy', marker='o')\n    plt.plot(epochs, dev_acc, label='Dev Accuracy', marker='o')\n    plt.axhline(y=test_acc, color='r', linestyle='--', label='Test Accuracy')  # Test accuracy as a horizontal line\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Accuracy Over Epochs')\n    plt.legend()\n\n    # Show the plots\n    plt.tight_layout()\n    plt.show()\n\n# Call the function\nplot_metrics(train_loss, dev_loss, train_acc, dev_acc, test_loss, test_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.111385Z","iopub.status.idle":"2024-11-26T19:57:54.111667Z","shell.execute_reply.started":"2024-11-26T19:57:54.111534Z","shell.execute_reply":"2024-11-26T19:57:54.111548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Assuming `net` is your trained model\nmodel_path = \"/kaggle/working/alzheimer_model.pth\"\ntorch.save(net.state_dict(), model_path)\nprint(f\"Model saved as {model_path}\")\n\nfrom IPython.display import FileLink\n\n# Generate a clickable download link\nFileLink(\"/kaggle/working/alzheimer_model.pth\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T20:03:24.465609Z","iopub.execute_input":"2024-11-26T20:03:24.466051Z","iopub.status.idle":"2024-11-26T20:03:24.707494Z","shell.execute_reply.started":"2024-11-26T20:03:24.466017Z","shell.execute_reply":"2024-11-26T20:03:24.706587Z"}},"outputs":[{"name":"stdout","text":"Model saved as /kaggle/working/alzheimer_model.pth\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/alzheimer_model.pth","text/html":"<a href='/kaggle/working/alzheimer_model.pth' target='_blank'>/kaggle/working/alzheimer_model.pth</a><br>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"import boto3\nimport os\nfrom botocore.exceptions import NoCredentialsError, PartialCredentialsError, ClientError\n\ndef download_from_s3(access_key, secret_key, region, bucket_name, file_path, download_path):\n    # Configure S3 client\n    s3 = boto3.client(\n        's3',\n        aws_access_key_id=access_key,\n        aws_secret_access_key=secret_key,\n        region_name=region,\n    )\n\n    # Download file from S3\n    try:\n        # Extract file name from the path\n        file_name = os.path.basename(file_path)\n        s3.download_file(bucket_name, file_name, download_path)\n        print(f\"File {file_name} downloaded successfully from {bucket_name} to {download_path}.\")\n    except FileNotFoundError:\n        print(f\"File not found: {file_path}\")\n    except NoCredentialsError:\n        print(\"AWS credentials not found.\")\n    except PartialCredentialsError:\n        print(\"Incomplete AWS credentials.\")\n    except Exception as e:\n        print(f\"File download failed: {e}\")\n\n# Replace these with your details\nACCESS_KEY = \"AKIAQEIP3UIEZ2M7N7U4\"\nSECRET_KEY = \"7m5p4JnB1BovPuXn/Avv9ljUoSNyILNpDFWKmX43\"\nREGION = \"ap-south-1\"  # Mumbai region\nBUCKET_NAME = \"Alzheimer\"  # Your actual S3 bucket name\nMODEL_FILE = \"alzheimer_model.pth\"  # The file you want to download from S3\nDOWNLOAD_PATH = \"C:/Users/Shahmir/Downloads/alzheimer_model.pth\"\"  # Where the file will be saved locally\n\n# Call the function to download the file\ndownload_from_s3(ACCESS_KEY, SECRET_KEY, REGION, BUCKET_NAME, MODEL_FILE, DOWNLOAD_PATH)\n\n# The file is now downloaded to DOWNLOAD_PATH, and you can use or share it\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.112967Z","iopub.status.idle":"2024-11-26T19:57:54.113353Z","shell.execute_reply.started":"2024-11-26T19:57:54.113116Z","shell.execute_reply":"2024-11-26T19:57:54.113141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install boto3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.114270Z","iopub.status.idle":"2024-11-26T19:57:54.114554Z","shell.execute_reply.started":"2024-11-26T19:57:54.114415Z","shell.execute_reply":"2024-11-26T19:57:54.114430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\n\nmodel_path = \"/kaggle/working/alzheimer_model.pth\"\n\n# Check if the file exists\nif os.path.exists(model_path):\n    # Generate a clickable download link\n    display(FileLink(model_path))\nelse:\n    print(f\"File not found at {model_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:57:54.125950Z","iopub.status.idle":"2024-11-26T19:57:54.126246Z","shell.execute_reply.started":"2024-11-26T19:57:54.126104Z","shell.execute_reply":"2024-11-26T19:57:54.126119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}